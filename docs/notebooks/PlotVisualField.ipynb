{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the data from the NPZ file\n",
    "data = np.load('/Users/tristan/Videos/data/group_1_visual_field_fish0.npz')\n",
    "kinematics = np.load('/Users/tristan/Videos/data/group_1_fish0.npz')\n",
    "\n",
    "my_id = kinematics['id'][0]\n",
    "cm_per_pixel = kinematics['cm_per_pixel'][0]\n",
    "headX, headY, headFrame = kinematics['X'] / cm_per_pixel, kinematics['Y'] / cm_per_pixel, kinematics['frame']\n",
    "print(\"kinematics: \", kinematics.files, \" my_id=\", my_id, \" cm_per_pixel=\", cm_per_pixel)\n",
    "\n",
    "# Extract the data arrays\n",
    "depth = data['depth']          # Shape: (len_frames, 2, layers, rays_per_layer)\n",
    "eye_pos = data['eye_pos']      # Shape: (len_frames, 2, 2)\n",
    "eye_angle = data['eye_angle']  # Shape: (len_frames, 2)\n",
    "fish_pos = data['fish_pos']    # Shape: (len_frames, 2)\n",
    "fish_angle = data['fish_angle']  # Shape: (len_frames,)\n",
    "frames = data['frames']        # Shape: (len_frames,)\n",
    "fov_range = data['fov_range']  # Shape: (2,)\n",
    "ids = data['ids']              # Shape: (len_frames, 2, rays_per_layer)\n",
    "visible_points = data['visible_points']  # Shape: (len_frames, 2, layers, rays_per_layer, 2)\n",
    "\n",
    "# Constants\n",
    "invalid_value = np.finfo(np.float32).max\n",
    "fov_start, fov_end = fov_range\n",
    "len_frames, num_eyes, num_layers, rays_per_layer = depth.shape\n",
    "vres = num_layers * rays_per_layer  # Total number of rays per eye\n",
    "\n",
    "# Define the frame range to process\n",
    "frame_start = 0      # Start frame number\n",
    "frame_end = 200      # End frame number\n",
    "\n",
    "# Find the indices of the frames in the data\n",
    "frame_indices = np.where((frames >= frame_start) & (frames <= frame_end))[0]\n",
    "\n",
    "# Video parameters\n",
    "video_width = 3700    # Video width in pixels\n",
    "video_height = 3700   # Video height in pixels\n",
    "fps = 30              # Frames per second\n",
    "\n",
    "# Initialize VideoWriter\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')  # Codec\n",
    "out = cv2.VideoWriter('visual_field.mp4', fourcc, fps, (video_width, video_height))\n",
    "\n",
    "# Create a black background image\n",
    "background = np.zeros((video_height, video_width, 3), dtype=np.uint8)\n",
    "\n",
    "# Iterate over the frames and plot the hit points for each eye\n",
    "for idx in tqdm(frame_indices):\n",
    "    # Create a copy of the background for this frame\n",
    "    frame_img = background.copy()\n",
    "    frame_ids = []\n",
    "\n",
    "    # Process each eye (0: left eye, 1: right eye)\n",
    "    for eye_idx in range(2):\n",
    "        # Get eye position and angle for the current frame and eye\n",
    "        eye_position = eye_pos[idx, eye_idx]      # Shape: (2,)\n",
    "        eye_orientation = eye_angle[idx, eye_idx]  # Scalar\n",
    "\n",
    "        # Generate angles for the field of view\n",
    "        angles = np.linspace(fov_start, fov_end, rays_per_layer)\n",
    "\n",
    "        # Compute direction vectors for each ray\n",
    "        directions = np.stack([np.cos(angles), np.sin(angles)], axis=1)  # Shape: (rays_per_layer, 2)\n",
    "\n",
    "        # Get depth values for the current frame and eye\n",
    "        depth_values = depth[idx, eye_idx, 0, :]  # Shape: (rays_per_layer,)\n",
    "\n",
    "        # Filter out invalid depth values\n",
    "        valid_mask = depth_values < invalid_value\n",
    "\n",
    "        # Extract valid depth values and directions\n",
    "        depth_valid = np.sqrt(depth_values[valid_mask])  # Assuming depth_values are squared distances\n",
    "        directions_valid = directions[valid_mask]\n",
    "\n",
    "        # Compute hit points using eye position, orientation, direction, and depth\n",
    "        # Rotate directions by eye_orientation\n",
    "        rotation_matrix = np.array([[np.cos(eye_orientation), -np.sin(eye_orientation)],\n",
    "                                    [np.sin(eye_orientation),  np.cos(eye_orientation)]])\n",
    "        rotated_directions = directions_valid @ rotation_matrix.T\n",
    "\n",
    "        # Compute hit points\n",
    "        hit_points = eye_position + rotated_directions * depth_valid[:, np.newaxis]  # Shape: (N, 2)\n",
    "\n",
    "        # Convert positions to integer pixel coordinates\n",
    "        points = hit_points.astype(np.int32)\n",
    "\n",
    "        # Draw lines and points on the frame\n",
    "        color = (255, 0, 0) if eye_idx == 0 else (0, 0, 255)  # Color for each eye\n",
    "        eye_pos_int = eye_position.astype(np.int32)\n",
    "        for point in points:\n",
    "            if 0 <= point[0] < video_width and 0 <= point[1] < video_height:\n",
    "                # Draw a line from the eye position to the hit point\n",
    "                cv2.line(frame_img, tuple(eye_pos_int), tuple(point), color, 1)\n",
    "                # Draw the hit point\n",
    "                cv2.circle(frame_img, tuple(point), 1, color, -1)\n",
    "\n",
    "        # Second method: Using visible_points data directly\n",
    "        # Get visible points for the current frame and eye\n",
    "        hit_points = visible_points[idx, eye_idx, 0].reshape(-1, 2)\n",
    "\n",
    "        # Filter out invalid points\n",
    "        valid_points = hit_points[hit_points[:, 0] != invalid_value]\n",
    "\n",
    "        # Convert positions to integer pixel coordinates\n",
    "        points = valid_points.astype(np.int32)\n",
    "\n",
    "        valid_ids = ids[idx, eye_idx, 0, valid_mask]\n",
    "        frame_ids.append(valid_ids)\n",
    "\n",
    "        # Draw the points on the frame\n",
    "        color = (255, 255, 0) if eye_idx == 0 else (255, 0, 255)  # Different color\n",
    "        for point in points:\n",
    "            if 0 <= point[0] < video_width and 0 <= point[1] < video_height:\n",
    "                cv2.circle(frame_img, tuple(point), 1, color, -1)\n",
    "\n",
    "    frame_ids = np.unique(np.concatenate(frame_ids))\n",
    "    if my_id in frame_ids:\n",
    "        frame_ids = np.delete(frame_ids, np.where(frame_ids == my_id))\n",
    "\n",
    "    # Draw eye positions\n",
    "    for eye_idx in range(2):\n",
    "        eye_position = eye_pos[idx, eye_idx].astype(np.int32)\n",
    "        if 0 <= eye_position[0] < video_width and 0 <= eye_position[1] < video_height:\n",
    "            # Draw the eye position\n",
    "            cv2.circle(frame_img, tuple(eye_position), 5, (0, 255, 0), -1)  # Green for eye positions\n",
    "\n",
    "    # Draw fish head position\n",
    "    head_position = np.array((headX[idx], headY[idx]), dtype=np.int32)\n",
    "    cv2.circle(frame_img, tuple(head_position), 5, (255, 255, 255), -1)  # White for fish head\n",
    "\n",
    "    cv2.putText(frame_img, f'Fish ID: {my_id}', (50, 50),\n",
    "                cv2.FONT_HERSHEY_DUPLEX, 1, (255, 255, 255), 2)\n",
    "    # Add frame number text\n",
    "    cv2.putText(frame_img, f'Frame {frames[idx]}', (50, 80),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "    # Add visible IDs text\n",
    "    cv2.putText(frame_img, f'Visible IDs: {frame_ids}', (50, 110),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    # Write the frame to the video\n",
    "    out.write(frame_img)\n",
    "\n",
    "    # Optionally, display the frame every 100 frames\n",
    "    #if idx % 100 == 0:\n",
    "    #    print(f'Processed frame {idx}/{len(frame_indices)}')\n",
    "    #    plt.imshow(cv2.cvtColor(frame_img, cv2.COLOR_BGR2RGB))\n",
    "    #    plt.axis('off')\n",
    "    #    plt.show()\n",
    "\n",
    "# Release the VideoWriter\n",
    "out.release()\n",
    "\n",
    "print('Video saved as visual_field.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -i visual_field.mp4 -c:v h264_videotoolbox -profile:v high -crf 20 -pix_fmt yuv420p visual_field_compressed.mp4 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import Video\n",
    "Video('visual_field_compressed.mp4', embed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "print(glob.glob(\"/Users/tristan/Videos/group_1_*_history.npz\"))\n",
    "with np.load(\"/Users/tristan/Videos/group_1_weights_-2_history.npz\") as npz:\n",
    "    print(list(npz.keys()))\n",
    "    print(npz[\"uniquenesses\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
