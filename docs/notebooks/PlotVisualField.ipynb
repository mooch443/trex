{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "kinematics:  ['normalized_midline', 'midline_y', 'X', 'ACCELERATION#pcentroid', 'X#wcentroid', 'time', 'midline_x', 'BORDER_DISTANCE#pcentroid', 'VY', 'frame', 'SPEED#wcentroid', 'midline_segment_length', 'num_pixels', 'MIDLINE_OFFSET', 'midline_length', 'VX', 'ACCELERATION#wcentroid', 'ANGULAR_A#centroid', 'ANGULAR_V#centroid', 'ANGLE', 'missing', 'SPEED#pcentroid', 'timestamp', 'Y#wcentroid', 'AY', 'AX', 'Y', 'SPEED', 'tracklets', 'tracklet_vxys', 'cm_per_pixel', 'id', 'frame_rate', 'video_size']  my_id= 0  cm_per_pixel= 0.004999999888241291\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "OpenCV: FFMPEG: tag 0x47504a4d/'MJPG' is not supported with codec id 7 and format 'mp4 / MP4 (MPEG-4 Part 14)'\n",
      "OpenCV: FFMPEG: fallback to use tag 0x7634706d/'mp4v'\n",
      "100%|██████████| 201/201 [00:13<00:00, 14.69it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Video saved as visual_field.mp4\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "from tqdm import tqdm\n",
    "\n",
    "# Load the data from the NPZ file\n",
    "data = np.load('/Users/tristan/Videos/data/group_1_visual_field_fish0.npz')\n",
    "kinematics = np.load('/Users/tristan/Videos/data/group_1_fish0.npz')\n",
    "\n",
    "my_id = kinematics['id'][0]\n",
    "cm_per_pixel = kinematics['cm_per_pixel'][0]\n",
    "headX, headY, headFrame = kinematics['X'] / cm_per_pixel, kinematics['Y'] / cm_per_pixel, kinematics['frame']\n",
    "print(\"kinematics: \", kinematics.files, \" my_id=\", my_id, \" cm_per_pixel=\", cm_per_pixel)\n",
    "\n",
    "# Extract the data arrays\n",
    "depth = data['depth']          # Shape: (len_frames, 2, layers, rays_per_layer)\n",
    "eye_pos = data['eye_pos']      # Shape: (len_frames, 2, 2)\n",
    "eye_angle = data['eye_angle']  # Shape: (len_frames, 2)\n",
    "fish_pos = data['fish_pos']    # Shape: (len_frames, 2)\n",
    "fish_angle = data['fish_angle']  # Shape: (len_frames,)\n",
    "frames = data['frames']        # Shape: (len_frames,)\n",
    "fov_range = data['fov_range']  # Shape: (2,)\n",
    "ids = data['ids']              # Shape: (len_frames, 2, rays_per_layer)\n",
    "visible_points = data['visible_points']  # Shape: (len_frames, 2, layers, rays_per_layer, 2)\n",
    "\n",
    "# Constants\n",
    "invalid_value = np.finfo(np.float32).max\n",
    "fov_start, fov_end = fov_range\n",
    "len_frames, num_eyes, num_layers, rays_per_layer = depth.shape\n",
    "vres = num_layers * rays_per_layer  # Total number of rays per eye\n",
    "\n",
    "# Define the frame range to process\n",
    "frame_start = 0      # Start frame number\n",
    "frame_end = 200      # End frame number\n",
    "\n",
    "# Find the indices of the frames in the data\n",
    "frame_indices = np.where((frames >= frame_start) & (frames <= frame_end))[0]\n",
    "\n",
    "# Video parameters\n",
    "video_width = 3700    # Video width in pixels\n",
    "video_height = 3700   # Video height in pixels\n",
    "fps = 30              # Frames per second\n",
    "\n",
    "# Initialize VideoWriter\n",
    "fourcc = cv2.VideoWriter_fourcc(*'MJPG')  # Codec\n",
    "out = cv2.VideoWriter('visual_field.mp4', fourcc, fps, (video_width, video_height))\n",
    "\n",
    "# Create a black background image\n",
    "background = np.zeros((video_height, video_width, 3), dtype=np.uint8)\n",
    "\n",
    "# Iterate over the frames and plot the hit points for each eye\n",
    "for idx in tqdm(frame_indices):\n",
    "    # Create a copy of the background for this frame\n",
    "    frame_img = background.copy()\n",
    "    frame_ids = []\n",
    "\n",
    "    # Process each eye (0: left eye, 1: right eye)\n",
    "    for eye_idx in range(2):\n",
    "        # Get eye position and angle for the current frame and eye\n",
    "        eye_position = eye_pos[idx, eye_idx]      # Shape: (2,)\n",
    "        eye_orientation = eye_angle[idx, eye_idx]  # Scalar\n",
    "\n",
    "        # Generate angles for the field of view\n",
    "        angles = np.linspace(fov_start, fov_end, rays_per_layer)\n",
    "\n",
    "        # Compute direction vectors for each ray\n",
    "        directions = np.stack([np.cos(angles), np.sin(angles)], axis=1)  # Shape: (rays_per_layer, 2)\n",
    "\n",
    "        # Get depth values for the current frame and eye\n",
    "        depth_values = depth[idx, eye_idx, 0, :]  # Shape: (rays_per_layer,)\n",
    "\n",
    "        # Filter out invalid depth values\n",
    "        valid_mask = depth_values < invalid_value\n",
    "\n",
    "        # Extract valid depth values and directions\n",
    "        depth_valid = np.sqrt(depth_values[valid_mask])  # Assuming depth_values are squared distances\n",
    "        directions_valid = directions[valid_mask]\n",
    "\n",
    "        # Compute hit points using eye position, orientation, direction, and depth\n",
    "        # Rotate directions by eye_orientation\n",
    "        rotation_matrix = np.array([[np.cos(eye_orientation), -np.sin(eye_orientation)],\n",
    "                                    [np.sin(eye_orientation),  np.cos(eye_orientation)]])\n",
    "        rotated_directions = directions_valid @ rotation_matrix.T\n",
    "\n",
    "        # Compute hit points\n",
    "        hit_points = eye_position + rotated_directions * depth_valid[:, np.newaxis]  # Shape: (N, 2)\n",
    "\n",
    "        # Convert positions to integer pixel coordinates\n",
    "        points = hit_points.astype(np.int32)\n",
    "\n",
    "        # Draw lines and points on the frame\n",
    "        color = (255, 0, 0) if eye_idx == 0 else (0, 0, 255)  # Color for each eye\n",
    "        eye_pos_int = eye_position.astype(np.int32)\n",
    "        for point in points:\n",
    "            if 0 <= point[0] < video_width and 0 <= point[1] < video_height:\n",
    "                # Draw a line from the eye position to the hit point\n",
    "                cv2.line(frame_img, tuple(eye_pos_int), tuple(point), color, 1)\n",
    "                # Draw the hit point\n",
    "                cv2.circle(frame_img, tuple(point), 1, color, -1)\n",
    "\n",
    "        # Second method: Using visible_points data directly\n",
    "        # Get visible points for the current frame and eye\n",
    "        hit_points = visible_points[idx, eye_idx, 0].reshape(-1, 2)\n",
    "\n",
    "        # Filter out invalid points\n",
    "        valid_points = hit_points[hit_points[:, 0] != invalid_value]\n",
    "\n",
    "        # Convert positions to integer pixel coordinates\n",
    "        points = valid_points.astype(np.int32)\n",
    "\n",
    "        valid_ids = ids[idx, eye_idx, 0, valid_mask]\n",
    "        frame_ids.append(valid_ids)\n",
    "\n",
    "        # Draw the points on the frame\n",
    "        color = (255, 255, 0) if eye_idx == 0 else (255, 0, 255)  # Different color\n",
    "        for point in points:\n",
    "            if 0 <= point[0] < video_width and 0 <= point[1] < video_height:\n",
    "                cv2.circle(frame_img, tuple(point), 1, color, -1)\n",
    "\n",
    "    frame_ids = np.unique(np.concatenate(frame_ids))\n",
    "    if my_id in frame_ids:\n",
    "        frame_ids = np.delete(frame_ids, np.where(frame_ids == my_id))\n",
    "\n",
    "    # Draw eye positions\n",
    "    for eye_idx in range(2):\n",
    "        eye_position = eye_pos[idx, eye_idx].astype(np.int32)\n",
    "        if 0 <= eye_position[0] < video_width and 0 <= eye_position[1] < video_height:\n",
    "            # Draw the eye position\n",
    "            cv2.circle(frame_img, tuple(eye_position), 5, (0, 255, 0), -1)  # Green for eye positions\n",
    "\n",
    "    # Draw fish head position\n",
    "    head_position = np.array((headX[idx], headY[idx]), dtype=np.int32)\n",
    "    cv2.circle(frame_img, tuple(head_position), 5, (255, 255, 255), -1)  # White for fish head\n",
    "\n",
    "    cv2.putText(frame_img, f'Fish ID: {my_id}', (50, 50),\n",
    "                cv2.FONT_HERSHEY_DUPLEX, 1, (255, 255, 255), 2)\n",
    "    # Add frame number text\n",
    "    cv2.putText(frame_img, f'Frame {frames[idx]}', (50, 80),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "    # Add visible IDs text\n",
    "    cv2.putText(frame_img, f'Visible IDs: {frame_ids}', (50, 110),\n",
    "                cv2.FONT_HERSHEY_SIMPLEX, 1, (255, 255, 255), 2)\n",
    "\n",
    "    # Write the frame to the video\n",
    "    out.write(frame_img)\n",
    "\n",
    "    # Optionally, display the frame every 100 frames\n",
    "    #if idx % 100 == 0:\n",
    "    #    print(f'Processed frame {idx}/{len(frame_indices)}')\n",
    "    #    plt.imshow(cv2.cvtColor(frame_img, cv2.COLOR_BGR2RGB))\n",
    "    #    plt.axis('off')\n",
    "    #    plt.show()\n",
    "\n",
    "# Release the VideoWriter\n",
    "out.release()\n",
    "\n",
    "print('Video saved as visual_field.mp4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ffmpeg version 7.1.1 Copyright (c) 2000-2025 the FFmpeg developers\n",
      "  built with clang version 18.1.8\n",
      "  configuration: --prefix=/Users/tristan/miniforge3/envs/jupyter2 --cc=arm64-apple-darwin20.0.0-clang --cxx=arm64-apple-darwin20.0.0-clang++ --nm=arm64-apple-darwin20.0.0-nm --ar=arm64-apple-darwin20.0.0-ar --disable-doc --enable-openssl --enable-demuxer=dash --enable-hardcoded-tables --enable-libfreetype --enable-libharfbuzz --enable-libfontconfig --enable-libopenh264 --enable-libdav1d --enable-cross-compile --arch=arm64 --target-os=darwin --cross-prefix=arm64-apple-darwin20.0.0- --host-cc=/Users/runner/miniforge3/conda-bld/ffmpeg_1743376098333/_build_env/bin/x86_64-apple-darwin13.4.0-clang --enable-neon --disable-gnutls --enable-libvpx --enable-libass --enable-pthreads --enable-libopenvino --enable-gpl --enable-libx264 --enable-libx265 --enable-libmp3lame --enable-libaom --enable-libsvtav1 --enable-libxml2 --enable-pic --enable-shared --disable-static --enable-version3 --enable-zlib --enable-libvorbis --enable-libopus --enable-librsvg --enable-ffplay --pkg-config=/Users/runner/miniforge3/conda-bld/ffmpeg_1743376098333/_build_env/bin/pkg-config\n",
      "  libavutil      59. 39.100 / 59. 39.100\n",
      "  libavcodec     61. 19.101 / 61. 19.101\n",
      "  libavformat    61.  7.100 / 61.  7.100\n",
      "  libavdevice    61.  3.100 / 61.  3.100\n",
      "  libavfilter    10.  4.100 / 10.  4.100\n",
      "  libswscale      8.  3.100 /  8.  3.100\n",
      "  libswresample   5.  3.100 /  5.  3.100\n",
      "  libpostproc    58.  3.100 / 58.  3.100\n",
      "Input #0, mov,mp4,m4a,3gp,3g2,mj2, from 'visual_field.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf61.7.100\n",
      "  Duration: 00:00:06.70, start: 0.000000, bitrate: 36191 kb/s\n",
      "  Stream #0:0[0x1](und): Video: mjpeg (Baseline) (mp4v / 0x7634706D), yuvj420p(pc, bt470bg/unknown/unknown), 3700x3700, 36189 kb/s, 30 fps, 30 tbr, 15360 tbn (default)\n",
      "      Metadata:\n",
      "        handler_name    : VideoHandler\n",
      "        vendor_id       : [0][0][0][0]\n",
      "\u001b[1;35m[out#0/mp4 @ 0x1581056f0] \u001b[0m\u001b[0;33mCodec AVOption crf (Select the quality for constant quality mode) has not been used for any stream. The most likely reason is either wrong type (e.g. a video option with no video streams) or that it is a private option of some decoder which was not actually used for any stream.\n",
      "\u001b[0mStream mapping:\n",
      "  Stream #0:0 -> #0:0 (mjpeg (native) -> h264 (h264_videotoolbox))\n",
      "Press [q] to stop, [?] for help\n",
      "\u001b[1;34m[swscaler @ 0x140700000] \u001b[0m\u001b[0;33mdeprecated pixel format used, make sure you did set range correctly\n",
      "\u001b[0mOutput #0, mp4, to 'visual_field_compressed.mp4':\n",
      "  Metadata:\n",
      "    major_brand     : isom\n",
      "    minor_version   : 512\n",
      "    compatible_brands: isomiso2mp41\n",
      "    encoder         : Lavf61.7.100\n",
      "  Stream #0:0(und): Video: h264 (avc1 / 0x31637661), yuv420p(pc, bt470bg/unknown/unknown, progressive), 3700x3700, q=2-31, 30 fps, 15360 tbn (default)\n",
      "      Metadata:\n",
      "        handler_name    : VideoHandler\n",
      "        vendor_id       : [0][0][0][0]\n",
      "        encoder         : Lavc61.19.101 h264_videotoolbox\n",
      "\u001b[1;35m[out#0/mp4 @ 0x1581056f0] \u001b[0mvideo:7441KiB audio:0KiB subtitle:0KiB other streams:0KiB global headers:0KiB muxing overhead: 0.023623%\n",
      "frame=  201 fps= 31 q=-0.0 Lsize=    7443KiB time=00:00:06.66 bitrate=9145.6kbits/s speed=1.03x    \n"
     ]
    }
   ],
   "source": [
    "!ffmpeg -i visual_field.mp4 -c:v h264_videotoolbox -profile:v high -crf 20 -pix_fmt yuv420p visual_field_compressed.mp4 -y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from IPython.display import Video\n",
    "Video('visual_field_compressed.mp4', embed=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['/Users/tristan/Videos/group_1_weights_4_history.npz', '/Users/tristan/Videos/group_1_weights_13_history.npz', '/Users/tristan/Videos/group_1_weights_8_history.npz', '/Users/tristan/Videos/group_1_weights_1_history.npz', '/Users/tristan/Videos/group_1_weights_15_history.npz', '/Users/tristan/Videos/group_1_weights_2_history.npz', '/Users/tristan/Videos/group_1_weights_-2_history.npz', '/Users/tristan/Videos/group_1_weights_10_history.npz', '/Users/tristan/Videos/group_1_weights_7_history.npz', '/Users/tristan/Videos/group_1_weights_17_history.npz', '/Users/tristan/Videos/group_1_weights_0_history.npz', '/Users/tristan/Videos/group_1_weights_9_history.npz', '/Users/tristan/Videos/group_1_range_history.npz', '/Users/tristan/Videos/group_1_weights_12_history.npz', '/Users/tristan/Videos/group_1_weights_5_history.npz', '/Users/tristan/Videos/group_1_weights_6_history.npz', '/Users/tristan/Videos/group_1_weights_11_history.npz', '/Users/tristan/Videos/group_1_weights_3_history.npz', '/Users/tristan/Videos/group_1_weights_14_history.npz']\n",
      "['uniquenesses', 'better_values', 'much_better_values', 'worst_values', 'mean_values', 'settings', 'per_class_accuracy', 'samples_per_class']\n",
      "[0.98406494 0.97949135 0.985412   0.98286337 0.98670298 0.98330605\n",
      " 0.98777789 0.97802949 0.98909366 0.98922414 0.98825723 0.98711896\n",
      " 0.98462307 0.99030823 0.99026859 0.98492712 0.98841751 0.99027693\n",
      " 0.98713052 0.99008411 0.99093264 0.98703724 0.98616284 0.98050511\n",
      " 0.98953736 0.97413397 0.98860914 0.98871577 0.99182904 0.99028426\n",
      " 0.97989845 0.98887765 0.98769331 0.98798215 0.98938477 0.98798221\n",
      " 0.98922694]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import glob\n",
    "print(glob.glob(\"/Users/tristan/Videos/group_1_*_history.npz\"))\n",
    "with np.load(\"/Users/tristan/Videos/group_1_weights_-2_history.npz\") as npz:\n",
    "    print(list(npz.keys()))\n",
    "    print(npz[\"uniquenesses\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jupyter2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.20"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
